#!/usr/bin/env python3
"""
GRIBæ•°æ®å¤„ç†è„šæœ¬ - ä¸“é—¨å¤„ç†CAMS GRIBæ ¼å¼çš„PM2.5æ•°æ®
"""

import xarray as xr
import numpy as np
import rasterio
from rasterio.transform import from_bounds
from rasterio.crs import CRS
import os
import sys
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

class GRIBDataProcessor:
    def __init__(self):
        self.target_crs = "EPSG:4326"  # WGS84
        self.web_mercator_crs = "EPSG:3857"  # Web Mercator for tiles
    
    def process_grib_pm25_for_tiles(self, grib_file, output_dir="data_pipeline/data/processed/pm25"):
        """
        å¤„ç†GRIBæ ¼å¼çš„PM2.5æ•°æ®ä¸ºç“¦ç‰‡ç”Ÿæˆå‡†å¤‡
        
        Args:
            grib_file: è¾“å…¥GRIBæ–‡ä»¶
            output_dir: è¾“å‡ºç›®å½•
        """
        logger.info(f"å¼€å§‹å¤„ç†GRIBæ•°æ®æ–‡ä»¶: {grib_file}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        try:
            # ä½¿ç”¨cfgribè¯»å–GRIBæ•°æ®
            logger.info("æ­£åœ¨è¯»å–GRIBæ–‡ä»¶...")
            ds = xr.open_dataset(grib_file, engine='cfgrib')
            
            logger.info("GRIBæ–‡ä»¶è¯»å–æˆåŠŸ")
            logger.info(f"æ•°æ®å˜é‡: {list(ds.data_vars.keys())}")
            logger.info(f"åæ ‡: {list(ds.coords.keys())}")
            logger.info(f"æ•°æ®å½¢çŠ¶: {ds.dims}")
            
            # æŸ¥æ‰¾PM2.5å˜é‡ (GRIBæ–‡ä»¶ä¸­å¯èƒ½æœ‰ä¸åŒçš„å˜é‡å)
            pm25_vars = []
            for var in ds.data_vars:
                var_name = str(var).lower()
                if any(keyword in var_name for keyword in ['pm2p5', 'pm25', 'particulate', 'mass_density', 'dust']):
                    pm25_vars.append(var)
                    logger.info(f"æ‰¾åˆ°å¯èƒ½çš„PM2.5å˜é‡: {var}")
                    if hasattr(ds[var], 'long_name'):
                        logger.info(f"  é•¿åç§°: {ds[var].long_name}")
                    if hasattr(ds[var], 'units'):
                        logger.info(f"  å•ä½: {ds[var].units}")
            
            if not pm25_vars:
                # å¦‚æœæ²¡æ‰¾åˆ°æ˜ç¡®çš„PM2.5å˜é‡ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®å˜é‡
                pm25_vars = [list(ds.data_vars.keys())[0]]
                logger.warning(f"æœªæ‰¾åˆ°æ˜ç¡®çš„PM2.5å˜é‡ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå˜é‡: {pm25_vars[0]}")
            
            pm25_var = pm25_vars[0]
            pm25_data = ds[pm25_var]
            
            logger.info(f"ä½¿ç”¨å˜é‡: {pm25_var}")
            logger.info(f"åŸå§‹æ•°æ®å½¢çŠ¶: {pm25_data.shape}")
            logger.info(f"åŸå§‹æ•°æ®å•ä½: {pm25_data.attrs.get('units', 'unknown')}")
            logger.info(f"åŸå§‹æ•°æ®èŒƒå›´: {pm25_data.min().item():.2e} - {pm25_data.max().item():.2e}")
            
            # å¤„ç†æ•°æ®çš„å•ä½å’Œç»´åº¦
            # GRIBæ–‡ä»¶é€šå¸¸åŒ…å«å¤šä¸ªæ—¶é—´æ­¥ (stepç»´åº¦)
            if 'step' in pm25_data.dims:
                logger.info(f"æ­¥é•¿ç»´åº¦: {len(pm25_data.step)} ä¸ªæ—¶é—´æ­¥")
                logger.info(f"æ­¥é•¿èŒƒå›´: {pm25_data.step.min().values} åˆ° {pm25_data.step.max().values}")
                
                # è®¡ç®—æ—¶é—´å¹³å‡å€¼
                pm25_mean = pm25_data.mean(dim='step', skipna=True)
                logger.info("è®¡ç®—æ­¥é•¿å¹³å‡å€¼")
            elif 'time' in pm25_data.dims:
                logger.info(f"æ—¶é—´ç»´åº¦: {len(pm25_data.time)} ä¸ªæ—¶é—´æ­¥")
                logger.info(f"æ—¶é—´èŒƒå›´: {pm25_data.time.min().values} åˆ° {pm25_data.time.max().values}")
                
                # è®¡ç®—æ—¶é—´å¹³å‡å€¼
                pm25_mean = pm25_data.mean(dim='time', skipna=True)
                logger.info("è®¡ç®—æ—¶é—´å¹³å‡å€¼")
            else:
                pm25_mean = pm25_data
                logger.info("æ•°æ®ä¸åŒ…å«æ—¶é—´æˆ–æ­¥é•¿ç»´åº¦")
            
            # æ£€æŸ¥å’Œè½¬æ¢å•ä½
            if hasattr(pm25_data, 'units'):
                units = pm25_data.units
                if units == 'kg m**-3':
                    # è½¬æ¢ kg/mÂ³ â†’ Î¼g/mÂ³
                    pm25_ugm3 = pm25_mean * 1e9
                    logger.info("å•ä½è½¬æ¢: kg/mÂ³ â†’ Î¼g/mÂ³")
                elif units == 'kg kg**-1':
                    # å‡è®¾è¿‘åœ°é¢ç©ºæ°”å¯†åº¦çº¦ä¸º 1.2 kg/mÂ³
                    pm25_ugm3 = pm25_mean * 1.2 * 1e9
                    logger.info("å•ä½è½¬æ¢: kg/kg â†’ Î¼g/mÂ³ (å‡è®¾ç©ºæ°”å¯†åº¦ 1.2 kg/mÂ³)")
                else:
                    pm25_ugm3 = pm25_mean
                    logger.warning(f"æœªçŸ¥å•ä½: {units}, ä¸è¿›è¡Œè½¬æ¢")
            else:
                # æ£€æŸ¥æ•°æ®èŒƒå›´æ¥æ¨æµ‹å•ä½
                data_max = pm25_mean.max().item()
                if data_max < 1e-6:
                    # å¾ˆå¯èƒ½æ˜¯ kg/mÂ³
                    pm25_ugm3 = pm25_mean * 1e9
                    logger.info("æ ¹æ®æ•°æ®èŒƒå›´æ¨æµ‹å•ä½è½¬æ¢: kg/mÂ³ â†’ Î¼g/mÂ³")
                else:
                    pm25_ugm3 = pm25_mean
                    logger.info("æ•°æ®èŒƒå›´æ˜¾ç¤ºå¯èƒ½å·²ç»æ˜¯ Î¼g/mÂ³")
            
            logger.info(f"å¤„ç†åæ•°æ®èŒƒå›´: {pm25_ugm3.min().item():.2f} - {pm25_ugm3.max().item():.2f} Î¼g/mÂ³")
            
            # è¾“å‡ºå¤„ç†åçš„æ•°æ® (NetCDFæ ¼å¼)
            output_file = os.path.join(output_dir, "pm25_qld_cams_processed.nc")
            
            # æ›´æ–°å±æ€§
            pm25_ugm3.attrs = {
                'long_name': 'CAMS PM2.5 mass concentration (time-averaged)',
                'units': 'Î¼g m-3',
                'standard_name': 'mass_concentration_of_pm2p5_ambient_aerosol_particles_in_air',
                'description': 'Real CAMS PM2.5 data processed for tile generation',
                'source': 'ECMWF CAMS Global Atmospheric Composition Forecasts'
            }
            
            pm25_ugm3.to_netcdf(output_file)
            logger.info(f"å¤„ç†åæ•°æ®ä¿å­˜: {output_file}")
            
            # ç”ŸæˆGeoTIFF (ç”¨äºç“¦ç‰‡ç”Ÿæˆ)
            geotiff_file = self.export_to_geotiff(pm25_ugm3, output_dir)
            
            return output_file, geotiff_file
            
        except Exception as e:
            logger.error(f"GRIBæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            raise
        finally:
            if 'ds' in locals():
                ds.close()
    
    def export_to_geotiff(self, data_array, output_dir):
        """å¯¼å‡ºä¸ºGeoTIFFæ ¼å¼"""
        geotiff_file = os.path.join(output_dir, "pm25_qld_cams_processed.tif")
        
        logger.info(f"å¯¼å‡ºGeoTIFF: {geotiff_file}")
        
        # è·å–åæ ‡
        lats = data_array.latitude.values
        lons = data_array.longitude.values
        
        logger.info(f"ç»åº¦èŒƒå›´: {lons.min():.2f} - {lons.max():.2f}")
        logger.info(f"çº¬åº¦èŒƒå›´: {lats.min():.2f} - {lats.max():.2f}")
        
        # æ£€æŸ¥åæ ‡é¡ºåº
        if lats[0] < lats[-1]:
            logger.info("çº¬åº¦éœ€è¦ç¿»è½¬ (å—â†’åŒ— æ”¹ä¸º åŒ—â†’å—)")
            data_values = np.flipud(data_array.values)
            lats = lats[::-1]
        else:
            data_values = data_array.values
        
        # åˆ›å»ºå˜æ¢çŸ©é˜µ
        transform = from_bounds(
            lons.min(), lats.min(), 
            lons.max(), lats.max(),
            len(lons), len(lats)
        )
        
        # å¤„ç†NaNå€¼
        data_values = np.nan_to_num(data_values, nan=0.0)
        
        # å†™å…¥GeoTIFF
        with rasterio.open(
            geotiff_file, 'w',
            driver='GTiff',
            height=len(lats),
            width=len(lons),
            count=1,
            dtype=rasterio.float32,
            crs=self.target_crs,
            transform=transform,
            compress='lzw',
        ) as dst:
            dst.write(data_values.astype(rasterio.float32), 1)
            
            # æ·»åŠ å…ƒæ•°æ®
            dst.update_tags(
                AREA_OR_POINT='Area',
                DESCRIPTION='CAMS PM2.5 mass concentration for Queensland, Australia',
                UNITS='Î¼g/mÂ³',
                SOURCE='ECMWF CAMS Global Atmospheric Composition Forecasts'
            )
        
        # éªŒè¯GeoTIFF
        with rasterio.open(geotiff_file) as src:
            logger.info(f"GeoTIFFéªŒè¯: {src.width} x {src.height} pixels")
            logger.info(f"æŠ•å½±åæ ‡ç³»: {src.crs}")
            logger.info(f"æ•°æ®èŒƒå›´: {src.read(1).min():.2f} - {src.read(1).max():.2f}")
        
        logger.info(f"GeoTIFFå¯¼å‡ºå®Œæˆ: {geotiff_file}")
        return geotiff_file
    
    def inspect_grib_file(self, grib_file):
        """æ£€æŸ¥GRIBæ–‡ä»¶å†…å®¹"""
        logger.info(f"æ£€æŸ¥GRIBæ–‡ä»¶: {grib_file}")
        
        try:
            ds = xr.open_dataset(grib_file, engine='cfgrib')
            
            print("=== GRIBæ–‡ä»¶ä¿¡æ¯ ===")
            print(f"æ–‡ä»¶: {grib_file}")
            print(f"å¤§å°: {os.path.getsize(grib_file) / 1024:.2f} KB")
            print()
            
            print("æ•°æ®å˜é‡:")
            for var in ds.data_vars:
                print(f"  {var}:")
                if hasattr(ds[var], 'long_name'):
                    print(f"    é•¿åç§°: {ds[var].long_name}")
                if hasattr(ds[var], 'units'):
                    print(f"    å•ä½: {ds[var].units}")
                print(f"    å½¢çŠ¶: {ds[var].shape}")
                print(f"    ç»´åº¦: {ds[var].dims}")
                print(f"    æ•°æ®èŒƒå›´: {ds[var].min().item():.2e} - {ds[var].max().item():.2e}")
                print()
            
            print("åæ ‡:")
            for coord in ds.coords:
                print(f"  {coord}: {ds.coords[coord].shape} {ds.coords[coord].dims}")
                if coord in ['time']:
                    print(f"    èŒƒå›´: {ds.coords[coord].min().values} åˆ° {ds.coords[coord].max().values}")
                else:
                    print(f"    èŒƒå›´: {ds.coords[coord].min().item():.2f} åˆ° {ds.coords[coord].max().item():.2f}")
            
            print(f"\nå…¨å±€å±æ€§:")
            for attr in ds.attrs:
                print(f"  {attr}: {ds.attrs[attr]}")
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥GRIBæ–‡ä»¶å¤±è´¥: {e}")
        finally:
            if 'ds' in locals():
                ds.close()

def main():
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    if len(sys.argv) > 1:
        grib_file = sys.argv[1]
    else:
        # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„GRIBæ–‡ä»¶
        data_dir = Path("data_pipeline/data/raw/pm25")
        grib_files = list(data_dir.glob("*.grib"))
        
        if not grib_files:
            print("âŒ æœªæ‰¾åˆ°GRIBæ•°æ®æ–‡ä»¶")
            print("   è¯·å…ˆè¿è¡Œ: python data_pipeline/downloads/pm25/download_pm25.py")
            sys.exit(1)
        
        # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
        grib_file = max(grib_files, key=os.path.getctime)
    
    try:
        processor = GRIBDataProcessor()
        
        # å…ˆæ£€æŸ¥æ–‡ä»¶å†…å®¹
        print("ğŸ” æ£€æŸ¥GRIBæ–‡ä»¶å†…å®¹:")
        processor.inspect_grib_file(str(grib_file))
        print()
        
        # å¤„ç†æ•°æ®
        print("âš™ï¸ å¼€å§‹å¤„ç†æ•°æ®...")
        processed_file, geotiff_file = processor.process_grib_pm25_for_tiles(str(grib_file))
        
        print("âœ… GRIBæ•°æ®å¤„ç†å®Œæˆ!")
        print(f"ğŸ“„ å¤„ç†åNetCDF: {processed_file}")
        print(f"ğŸ—ºï¸  GeoTIFFæ–‡ä»¶: {geotiff_file}")
        print("\nğŸ“ ä¸‹ä¸€æ­¥:")
        print("   python data_pipeline/processing/common/generate_tiles.py data_pipeline/data/processed/pm25/pm25_qld_cams_processed.tif")
        
    except Exception as e:
        print(f"âŒ GRIBæ•°æ®å¤„ç†å¤±è´¥: {e}")
        logger.error(f"GRIBæ•°æ®å¤„ç†å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
